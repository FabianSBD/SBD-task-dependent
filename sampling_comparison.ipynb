{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ebeec7-c03e-4a0a-b4b5-5c48cecc51d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.utils import make_grid\n",
    "import time\n",
    "\n",
    "from csgm import ConditionalScoreModel2D, ConditionalScoreModel2Dy\n",
    "from csgm.utils import CustomLRScheduler\n",
    "\n",
    "from utils_ours import uncond_loss_fn, our_loss_fn\n",
    "from samplers import *\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bacf476-c3fa-4771-ad9e-ef3d87df7a37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "T = 1\n",
    "\n",
    "size = 64\n",
    "\n",
    "dataset_str = \"LIDC\" #@param ['LIDC', 'MNIST'] {'type':'string'}\n",
    "\n",
    "\n",
    "eps = 5e-3\n",
    "device = \"cuda\"\n",
    "\n",
    "inv_prob = \"ct\"#@param ['ct', 'deblurr'] {'type':'string'}\n",
    "\n",
    "\n",
    "batch_size = 1000\n",
    "num_samples =  1000#@param {\"type\":\"integer\"}\n",
    "\n",
    "## Parameters below are fixed for our experiment. Changing them will require training a new model for our approach.\n",
    "\n",
    "\n",
    "sig_blurr = 5\n",
    "\n",
    "max_angle = 45\n",
    "color_channels = 1\n",
    "\n",
    "#angles = int(size * max_angle / 180.)\n",
    "angles = size\n",
    "\n",
    "num_steps = 1000\n",
    "\n",
    "\n",
    "if dataset_str == \"LIDC\":\n",
    "    lr= 0.002 #@param {'type':'number'}\n",
    "    lr_final = 0.0005\n",
    "    from utils_ours import LungDataset\n",
    "\n",
    "    dataset = LungDataset(train = False,\n",
    "                       transform=torchvision.transforms.Compose(\n",
    "                           [torchvision.transforms.Resize(size, antialias=True), torchvision.transforms.Lambda(lambda x: x.permute(1, 2, 0))]))\n",
    "\n",
    "    val_data_loader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "    sig_obs = 0.05\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64d6cd1-0668-4038-b8a0-9f53b38adfe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Load the score-based model\n",
    "\n",
    "\n",
    "if True:\n",
    "    #prepare forward map and other required parameters\n",
    "    if inv_prob == \"deblurr\":\n",
    "        from utils_ours import build_blurring_operator\n",
    "        A = build_blurring_operator(size, sig_blurr).to(device)\n",
    "    elif inv_prob == \"ct\":\n",
    "        from utils_ours import build_CT_operator\n",
    "        try:\n",
    "            A = torch.load(\"CT_forward\" + str(size) + \"angles\" + str(angles) + \"max_angle\" + str(max_angle) +\".pt\")\n",
    "        except:\n",
    "            A = build_CT_operator(size, angles, max_angle) \n",
    "        A = torch.from_numpy(A)\n",
    "\n",
    "A = A.to(device).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef46ce49-aa12-4d16-baa3-916836bb6c84",
   "metadata": {},
   "source": [
    "## Generate Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc4df76-16df-40e1-b03f-98fb594b08df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "torch.manual_seed(13)\n",
    "\n",
    "if dataset_str == 'MNIST':\n",
    "    true, _ = next(iter(val_data_loader))\n",
    "else:\n",
    "    true = next(iter(val_data_loader))\n",
    "\n",
    "\n",
    "plt.imshow(true[0, :, :, 0], cmap = 'gray')\n",
    "plt.colorbar()\n",
    "plt.grid(None) \n",
    "plt.axis('off')\n",
    "#plt.savefig(\"truth.jpg\")\n",
    "plt.show()\n",
    "\n",
    "true = true.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf71679c-fa95-4ba9-9f19-fd06a8fb1133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = A.float() @ true.reshape(size**2, -1).to(A.device).float()\n",
    "if inv_prob == \"ct\":\n",
    "    y = y.reshape((1, size, angles))\n",
    "elif inv_prob == \"deblurr\":\n",
    "    y = y.reshape((1, size, size))\n",
    "    \n",
    "y = y + sig_obs * torch.randn_like(y)\n",
    "y = y.cuda().float()\n",
    "\n",
    "sample_grid = make_grid(y / torch.max(y), nrow=1)\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.axis('off')\n",
    "plt.imshow(sample_grid.permute(1, 2, 0).cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a928efdc-b6a3-4901-8322-c04606460171",
   "metadata": {},
   "source": [
    "## Generate Posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8271768-5462-4005-84fc-8c67538c428c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = \"unconditional\" + \"_\" + \"T=\" + str(T)+ \"_\" + dataset_str\n",
    "\n",
    "\n",
    "cond_score_model_8 = ConditionalScoreModel2Dy(\n",
    "        modes=5,\n",
    "        hidden_dim=8,\n",
    "        nlayers=4,\n",
    "        nt=T\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "cond_score_model_16 = ConditionalScoreModel2Dy(\n",
    "        modes=5,\n",
    "        hidden_dim=16,\n",
    "        nlayers=4,\n",
    "        nt=T\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "cond_score_model_32 = ConditionalScoreModel2Dy(\n",
    "        modes=15,\n",
    "        hidden_dim=32,\n",
    "        nlayers=4,\n",
    "        nt=T\n",
    "    ).to(device)\n",
    "\n",
    "cond_score_model_64 = ConditionalScoreModel2Dy(\n",
    "        modes=15,\n",
    "        hidden_dim=64,\n",
    "        nlayers=4,\n",
    "        nt=T\n",
    "    ).to(device)\n",
    "\n",
    "cond_score_model_100 = ConditionalScoreModel2Dy(\n",
    "        modes=25,\n",
    "        hidden_dim=100,\n",
    "        nlayers=4,\n",
    "        nt=T\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "cond_score_model_128 = ConditionalScoreModel2Dy(\n",
    "        modes=25,\n",
    "        hidden_dim=128,\n",
    "        nlayers=4,\n",
    "        nt=T\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "cond_score_model_150 = ConditionalScoreModel2Dy(\n",
    "        modes=25,\n",
    "        hidden_dim=150,\n",
    "        nlayers=4,\n",
    "        nt=T\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "our_score_model_8 = ConditionalScoreModel2D(\n",
    "        modes=5,\n",
    "        hidden_dim=8,\n",
    "        nlayers=4,\n",
    "        nt=T\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "our_score_model_16 = ConditionalScoreModel2D(\n",
    "        modes=5,\n",
    "        hidden_dim=16,\n",
    "        nlayers=4,\n",
    "        nt=T\n",
    "    ).to(device)\n",
    "\n",
    "our_score_model_32 = ConditionalScoreModel2D(\n",
    "        modes=15,\n",
    "        hidden_dim=32,\n",
    "        nlayers=4,\n",
    "        nt=T\n",
    "    ).to(device)\n",
    "\n",
    "our_score_model_64 = ConditionalScoreModel2D(\n",
    "        modes=15,\n",
    "        hidden_dim=64,\n",
    "        nlayers=4,\n",
    "        nt=T\n",
    "    ).to(device)\n",
    "\n",
    "our_score_model_100 = ConditionalScoreModel2D(\n",
    "        modes=25,\n",
    "        hidden_dim=100,\n",
    "        nlayers=4,\n",
    "        nt=T\n",
    "    ).to(device)\n",
    "\n",
    "our_score_model_128 = ConditionalScoreModel2D(\n",
    "        modes=25,\n",
    "        hidden_dim=128,\n",
    "        nlayers=4,\n",
    "        nt=T\n",
    "    ).to(device)\n",
    "\n",
    "our_score_model_150 = ConditionalScoreModel2D(\n",
    "        modes=25,\n",
    "        hidden_dim=150,\n",
    "        nlayers=4,\n",
    "        nt=T\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "our_models = [our_score_model_8, our_score_model_16, our_score_model_32, our_score_model_64, our_score_model_100, our_score_model_128, our_score_model_150]\n",
    "cond_models = [cond_score_model_8, cond_score_model_16, cond_score_model_32, cond_score_model_64, cond_score_model_100, cond_score_model_128, cond_score_model_150]\n",
    "\n",
    "if inv_prob == \"ct\":\n",
    "    for i, hidden_dim in enumerate([8, 16, 32, 64, 100, 128, 150]):\n",
    "        filename = \"ours\" + \"_\" + \"T=\" + str(T)+ \"_\" + dataset_str + inv_prob + str(max_angle) + str(size)+ str(hidden_dim)\n",
    "        ckpt = torch.load(os.path.join(\"cpts\",\"ckpt_trained_\" + filename + \".pth\"), map_location=device)\n",
    "        our_models[i].load_state_dict(ckpt)\n",
    "        our_models[i].eval()\n",
    "    \n",
    "        filename = \"conditional\" + \"_\" + \"T=\" + str(T)+ \"_\" + dataset_str + inv_prob + str(max_angle)+ str(size)+ str(hidden_dim)\n",
    "        ckpt = torch.load(os.path.join(\"cpts\",\"ckpt_trained_\" + filename + \".pth\"), map_location=device)\n",
    "        cond_models[i].load_state_dict(ckpt)\n",
    "        cond_models[i].eval()\n",
    "elif inv_prob == \"deblurr\":\n",
    "    filename = \"ours\" + \"_\" + \"T=\" + str(T)+ \"_\" + dataset_str + inv_prob + str(sig_blurr)+ str(size)+ str(hidden_dim)\n",
    "    ckpt = torch.load(os.path.join(\"cpts\",\"ckpt_trained_\" + filename + \".pth\"), map_location=device)\n",
    "    our_score_model.load_state_dict(ckpt)#\n",
    "\n",
    "    filename = \"conditional\" + \"_\" + \"T=\" + str(T)+ \"_\" + dataset_str + inv_prob + str(sig_blurr)+ str(size)+ str(hidden_dim)\n",
    "    ckpt = torch.load(os.path.join(\"cpts\",\"ckpt_trained_\" + filename + \".pth\"), map_location=device)\n",
    "    cond_score_model.load_state_dict(ckpt)\n",
    "\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76566915-dd16-4e12-97d0-0a03f3237b19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Generate samples using the specified sampler.\n",
    "l2_conds = np.zeros(len(cond_models))\n",
    "std_conds = np.zeros(len(cond_models))\n",
    "bias_conds = np.zeros(len(cond_models))\n",
    "t_cond =  np.zeros(len(cond_models))\n",
    "for i, cond_score_model in enumerate(cond_models):\n",
    "    start = time.time()\n",
    "    samples = cond_sampler(cond_score_model, \n",
    "                      T = T,\n",
    "                      y = y.repeat((batch_size, 1, 1))[:, :, :, None],\n",
    "                      A = A, \n",
    "                      sig_obs = sig_obs,\n",
    "                      nsamples = num_samples,\n",
    "                      batch_size = batch_size, \n",
    "                      size = size,\n",
    "                      num_steps = num_steps,\n",
    "                      color_channels = 1,\n",
    "                      device=device,\n",
    "                      eps = eps)\n",
    "    stop = time.time()\n",
    "    print(\"time elapsed:\", stop - start)\n",
    "    ## Sample visualization.\n",
    "    samples = samples.clamp(0.0, 1.0)\n",
    "    %matplotlib inline\n",
    "    sample_grid = make_grid(samples, nrow=int(np.sqrt(num_samples)))\n",
    "    \n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(sample_grid.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    \n",
    "    std_cond = torch.std(samples, axis = 0)[0, :, :]\n",
    "    std_conds[i] = torch.mean(std_cond**2)**0.5\n",
    "    bias_cond = (torch.mean(samples, axis = 0) - true.to(samples.device)[0, :, :, 0])[0, :, :]\n",
    "    bias_conds[i] = torch.mean(bias_cond**2)**0.5\n",
    "    l2_cond = torch.mean((samples.cuda() - true[0, :, :, 0][None, None, :, :])**2)**0.5\n",
    "    l2_conds[i] = l2_cond.cpu().numpy()\n",
    "    t_cond[i] = stop - start\n",
    "\n",
    "    print(\"std:\" , torch.mean(std_cond**2)**0.5, \"bias:\", torch.mean(bias_cond**2)**0.5, \"l2:\", l2_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6637fa2-6539-464e-9686-ce9ada58aae2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Generate samples using the specified sampler.\n",
    "l2_ourss = np.zeros(len(cond_models))\n",
    "std_ourss = np.zeros(len(cond_models))\n",
    "bias_ourss = np.zeros(len(cond_models))\n",
    "t_ours = np.zeros(len(cond_models))\n",
    "for i, our_score_model in enumerate(our_models):\n",
    "    start = time.time()\n",
    "    samples = Our_sampler(our_score_model, \n",
    "                      T = T,\n",
    "                      y = y.repeat((num_samples, 1, 1)).reshape((num_samples, 1, A.shape[0])),\n",
    "                      A = A, \n",
    "                      sig_obs = sig_obs,\n",
    "                      nsamples = num_samples,\n",
    "                      batch_size = batch_size, \n",
    "                      size = size,\n",
    "                      num_steps = num_steps,\n",
    "                      color_channels = 1,\n",
    "                      device=device,\n",
    "                      eps = eps)\n",
    "    stop = time.time()\n",
    "    print(\"time elapsed:\", stop - start)\n",
    "    ## Sample visualization.p\n",
    "    samples = samples.clamp(0.0, 1.0)\n",
    "    %matplotlib inline\n",
    "    sample_grid = make_grid(samples, nrow=int(np.sqrt(num_samples)))\n",
    "    \n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(sample_grid.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    \n",
    "    std_ours = torch.std(samples, axis = 0)[0, :, :]\n",
    "    std_ourss[i] = torch.mean(std_ours**2)**0.5\n",
    "    bias_ours = (torch.mean(samples, axis = 0) - true.to(samples.device)[0, :, :, 0])[0, :, :]\n",
    "    bias_ourss[i] = torch.mean(bias_ours**2)**0.5\n",
    "    l2_ours = torch.mean((samples.cuda() - true[0, :, :, 0][None, None, :, :])**2)**0.5\n",
    "    l2_ourss[i] = l2_ours.cpu().numpy()\n",
    "    t_ours[i] = stop - start\n",
    "    \n",
    "    print(\"std:\" , torch.mean(std_ours**2)**0.5, \"bias:\", torch.mean(bias_ours**2)**0.5, \"l2:\", l2_ours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d94136-452c-4958-8421-2fbe2e67a839",
   "metadata": {},
   "source": [
    "## Exporting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f99662-b1a5-456e-96ce-436ef64e0902",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([8, 16, 32, 64, 100, 128, 150], l2_ourss, linestyle='--', marker='o', color='red', label='ours', linewidth=3, markersize=10)\n",
    "plt.plot([8, 16, 32, 64, 100, 128, 150], l2_conds, linestyle='--', marker='o', color = 'blue', label='conditional', linewidth=3, markersize=10)\n",
    "\n",
    "\n",
    "#plt.axis('off')\n",
    "plt.legend()\n",
    "plt.xlabel(\"nodes per layer\")\n",
    "plt.ylabel(\"L2\")\n",
    "plt.savefig(\"images/CT/graphl2.png\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66554dda-b70a-4aaf-873a-34b2c745f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([8, 16, 32, 64, 100, 128, 150], std_ourss, linestyle='--', marker='o', color = 'red', label = 'ours', linewidth=3, markersize=10)\n",
    "plt.plot([8, 16, 32, 64, 100, 128, 150], std_conds, linestyle='--', marker='o', color = 'blue', label = 'conditional', linewidth=3, markersize=10)\n",
    "\n",
    "plt.plot([32, 64, 128], [0.0344, 0.0319, 0.0298], linestyle='', marker='x', color='red', label='ours', linewidth=3, markersize=10)\n",
    "plt.plot([32, 64, 128], [0.0952, 0.0683, 0.0584], linestyle='', marker='x', color='blue', label='conditional', linewidth=3, markersize=10)\n",
    "#plt.axis('off')\n",
    "plt.legend()\n",
    "plt.xlabel(\"nodes per layer\")\n",
    "plt.ylabel(\"Std\")\n",
    "plt.savefig(\"images/CT/graphstd.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad0051-637e-4764-8975-ca7f3a1de2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([8, 16, 32, 64, 100, 128, 150], bias_ourss, linestyle='--', marker='o', color = 'red', label = 'ours', linewidth=3, markersize=10)\n",
    "plt.plot([8, 16, 32, 64, 100, 128, 150], bias_conds, linestyle='--', marker='o', color = 'blue', label = 'conditional', linewidth=3, markersize=10)\n",
    "\n",
    "plt.plot([32, 64, 128], [0.0489, 0.0477, 0.0443], linestyle='', marker='x', color='red', label='ours', linewidth=3, markersize=10)\n",
    "plt.plot([32, 64, 128], [0.2683, 0.0579, 0.0421], linestyle='', marker='x', color='blue', label='conditional', linewidth=3, markersize=10)\n",
    "#plt.axis('off')\n",
    "plt.legend()\n",
    "plt.xlabel(\"nodes per layer\")\n",
    "plt.ylabel(\"Bias\")\n",
    "plt.savefig(\"images/CT/graphbias.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b06877-0aff-42d6-88d4-199a56cd1cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
